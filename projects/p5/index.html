<!DOCTYPE html>
<html>
    <head>
        <title>Projecct 5</title>
    </head>
    <body>
        <script
          src="https://code.jquery.com/jquery-3.3.1.min.js"
          integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
          crossorigin="anonymous"></script>
        
        <video id="player" controls autoplay></video>
        <button id="capture">Capture</button>
        <canvas id="canvas" width=320 height=240></canvas>
        <div id="imageData" ></div>

        <script>
          const player = document.getElementById('player');
          const canvas = document.getElementById('canvas');
          const context = canvas.getContext('2d');
          const captureButton = document.getElementById('capture');
          var doFaceCapture = false;
          var visionApiEndpoint = "https://vision.googleapis.com/v1/images:annotate?key=";
          var nextX = 0, nextY = 0;
          
          const constraints = {
            video: true,
          };
         captureButton.addEventListener('click', () => {
           
            doFaceCapture = true;
            context.drawImage(player, 0, 0, canvas.width, canvas.height);
            getImageData('FACE_DETECTION');
          });
        
        
          navigator.mediaDevices.getUserMedia(constraints)
            .then((stream) => {
              player.srcObject = stream;
            });
         function getImageData(type) {  
         requestBody = {
                    "requests":[
                        {
                          "image":{
                            "content": canvas.toDataURL().split(",")[1]
                          },
                          "features":[
                            {
                              "type": type,
                              "maxResults": 1
                            }
                          ]
                        }
                      ]
                };
        $.ajax({
            method: "POST",
            contentType: "application/json",
            url: visionApiEndpoint+"?key=AIzaSyBijMwI7Leeu_i7MBF0hmpycUOZ2CG4jJU",
            data: JSON.stringify(requestBody)
        })
        .done(function(response){
                    console.log(response);
                    $("#image").html("<pre>" + JSON.stringify(response) + "</pre>")
                   
                    var faceVertices = response.responses[0].faceAnnotations[0].boundingPoly.vertices;
                    console.log(faceVertices);
                          
                    
                    var topLeft = faceVertices[0];
                    var bottomRight = faceVertices[2];
                    console.log(bottomRight, bottomRight.x, topLeft, topLeft.x);
                    
                    
                    var faceWidth = bottomRight.x - topLeft.x;
                    var faceHeight = bottomRight.y - topLeft.y;
                    var sourceX = topLeft.x;
                    var sourceY = topLeft.y;
                    
                    context.drawImage(canvas, sourceX, sourceY, faceWidth, faceHeight, nextX, nextY, faceWidth, faceHeight);
                    
                    nextX += faceWidth;
                  
                    if (doFaceCapture) {
                      getImageData('FACE_DETECTION');
                    }
                    
                });
            }
        </script>
        <script> 
        </script>
    </body>
</html>